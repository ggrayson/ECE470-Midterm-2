{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 470 Midterm 2 - Graham Grayson - V00878518\n",
    "\n",
    "### Question 1\n",
    "(a) Random Forest is a machine learning technique that works by randomly generating multiple decision trees and then returning the class that is the mode of the classes for classification or the mean of the classes for regression. It introduces a degree of randomness to the tree creation process that helps prevent overfitting. It works based on the idea that a group of weak decision trees can together become a strong decision tree.\n",
    "\n",
    "(b) Random Forest works best in classification problems, although it can work for regression as well. It works well for large datasets because the training time is fairly short. Random Forests are also able to deal with unbalanced and missing data. It is also easy to implement since it uses a low number of hyperparameters.\n",
    "\n",
    "(c) Yes, Random Forests can be used to rank feature importance. The approach described in the original paper on Random Forests is to first fit a forest while recording the error of each data point. This error is averaged over the entire forest. Then, the values of each feature being tested are permuted and the model is fitted again, and the error is again recorded and compared against the permuted values. For important features, the permutation of values should have a large impact on accuracy, while the opposite is true for unimportant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Note: This is partially based on a project I did for SENG474 (Datamining), which can be found at https://github.com/CallumThomas12/datamining-project-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>tbl_name</th>\n",
       "      <th>rootpage</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>table</td>\n",
       "      <td>craigslistVehiclesFull</td>\n",
       "      <td>craigslistVehiclesFull</td>\n",
       "      <td>2</td>\n",
       "      <td>CREATE TABLE \"craigslistVehiclesFull\" (\\n\"url\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                    name                tbl_name  rootpage  \\\n",
       "0  table  craigslistVehiclesFull  craigslistVehiclesFull         2   \n",
       "\n",
       "                                                 sql  \n",
       "0  CREATE TABLE \"craigslistVehiclesFull\" (\\n\"url\"...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "print(pd.__version__)\n",
    "#Note: I converted the spreadsheet to an SQLite dababase so I can use SQL\n",
    "conn = sqlite3.connect(\"C:\\cars.db\")\n",
    "tables = pd.read_sql(\"Select * from sqlite_master where type = 'table';\", conn)\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) I wrote an SQL query to extract the Los Angeles data (WHERE city = 'losangeles')\n",
    "\n",
    "(b) To start with I included the data features that seemed like they could be correlated to price. Features that were omitted were mainly done so because they had too many unique values that made them impossible to classify into numeric data, such as make. For the non-numeric features, I classified them into numeric categories to make it so the classifier can use them.\n",
    "\n",
    "Later on I tried calculating the correlation to find the best features, this can be found near the bottom of the notebook.\n",
    "\n",
    "(c) I checked for outliers in the numeric data and added upper/lower bounds on the price and odometer values. I dealt with missing data by specifying that all included features must have non-null values. This shrinks the dataset but also ensures that all the included data is complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  year  manufacturer  condition  cylinders  fuel  odometer  \\\n",
      "0      5450  2004            31          3          8     1    207000   \n",
      "1     12800  2016            37          3          4     4     34000   \n",
      "2      5995  2012            18          3          6     1     50000   \n",
      "3     24000  2006            15          4          8     3    203000   \n",
      "4       500  2002            32          4          6     1    175235   \n",
      "...     ...   ...           ...        ...        ...   ...       ...   \n",
      "1798  26900  2012            21          3          6     1     79600   \n",
      "1799   1100  1995            27          5          8     1    133000   \n",
      "1800   9500  2000             8          3          8     1     80000   \n",
      "1801   2000  1996            24          3          8     1         0   \n",
      "1802  17500  2015            34          6          6     3     39000   \n",
      "\n",
      "      transmission  drive  paint_color        lat   ABS(long)  \n",
      "0                2      3            9  34.167200  118.398900  \n",
      "1                2      2            9  34.184258  118.785896  \n",
      "2                2      1            6  47.464800  122.207500  \n",
      "3                2      3           11  36.276500  115.288500  \n",
      "4                2      2            1  33.892500  118.296100  \n",
      "...            ...    ...          ...        ...         ...  \n",
      "1798             2      3            1  33.905600  118.081800  \n",
      "1799             2      1            1  34.115500  118.085700  \n",
      "1800             1      1            2  34.187200  118.386500  \n",
      "1801             2      2            5  33.850631  118.264264  \n",
      "1802             2      1           10  32.680600  117.047400  \n",
      "\n",
      "[1803 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "price,\n",
    "year,\n",
    "CASE\n",
    "\tWHEN manufacturer = 'acura' THEN 1\n",
    "\tWHEN manufacturer = 'alfa-romeo' THEN 2\n",
    "    WHEN manufacturer = 'aston' THEN 3\n",
    "    WHEN manufacturer = 'aston-martin' THEN 3\n",
    "    WHEN manufacturer = 'audi' THEN 4\n",
    "    WHEN manufacturer = 'bmw' THEN 5\n",
    "    WHEN manufacturer = 'buick' THEN 6\n",
    "    WHEN manufacturer = 'cadillac' THEN 7\n",
    "    WHEN manufacturer = 'chev' THEN 8\n",
    "    WHEN manufacturer = 'chevrolet' THEN 8\n",
    "    WHEN manufacturer = 'chevy' THEN 8\n",
    "    WHEN manufacturer = 'chrysler' THEN 9\n",
    "    WHEN manufacturer = 'datsun' THEN 10\n",
    "    WHEN manufacturer = 'dodge' THEN 11\n",
    "    WHEN manufacturer = 'ferrari' THEN 12\n",
    "    WHEN manufacturer = 'fiat' THEN 13\n",
    "    WHEN manufacturer = 'ford' THEN 14\n",
    "    WHEN manufacturer = 'gmc' THEN 15\n",
    "    WHEN manufacturer = 'harley-davidson' THEN 16\n",
    "    WHEN manufacturer = 'honda' THEN 17\n",
    "    WHEN manufacturer = 'hyundai' THEN 18\n",
    "    WHEN manufacturer = 'infiniti' THEN 19\n",
    "    WHEN manufacturer = 'infinity' THEN 19\n",
    "    WHEN manufacturer = 'jaguar' THEN 20\n",
    "    WHEN manufacturer = 'jeep' THEN 21\n",
    "    WHEN manufacturer = 'kia' THEN 22\n",
    "    WHEN manufacturer = 'land rover' THEN 23\n",
    "    WHEN manufacturer = 'rover' THEN 23\n",
    "    WHEN manufacturer = 'lexus' THEN 24\n",
    "    WHEN manufacturer = 'lincoln' THEN 25\n",
    "    WHEN manufacturer = 'mazda' THEN 26\n",
    "    WHEN manufacturer = 'mercedes' THEN 27\n",
    "    WHEN manufacturer = 'mercedes-benz' THEN 27\n",
    "    WHEN manufacturer = 'mercury' THEN 28\n",
    "    WHEN manufacturer = 'mini' THEN 29\n",
    "    WHEN manufacturer = 'mitsubishi' THEN 30\n",
    "    WHEN manufacturer = 'nissan' THEN 31\n",
    "    WHEN manufacturer = 'pontiac' THEN 32\n",
    "    WHEN manufacturer = 'porche' THEN 33\n",
    "    WHEN manufacturer = 'ram' THEN 34\n",
    "    WHEN manufacturer = 'saturn' THEN 35\n",
    "    WHEN manufacturer = 'subaru' THEN 36\n",
    "    WHEN manufacturer = 'toyota' THEN 37\n",
    "    WHEN manufacturer = 'vw' THEN 38\n",
    "    WHEN manufacturer = 'volkswagen' THEN 38\n",
    "    WHEN manufacturer = 'volvo' THEN 39\n",
    "END AS manufacturer,\n",
    "CASE\n",
    "    WHEN condition = 'new' THEN 1\n",
    "    WHEN condition = 'like new' THEN 2\n",
    "    WHEN condition = 'excellent' THEN 3\n",
    "    WHEN condition = 'good' THEN 4\n",
    "    WHEN condition = 'fair' THEN 5\n",
    "    WHEN condition = 'salvage' THEN 6\n",
    "END AS condition,\n",
    "CASE\n",
    "    WHEN cylinders = '12 cylinders' THEN 12\n",
    "    WHEN cylinders = '10 cylinders' THEN 10\n",
    "    WHEN cylinders = '8 cylinders' THEN 8\n",
    "    WHEN cylinders = '6 cylinders' THEN 6\n",
    "    WHEN cylinders = '5 cylinders' THEN 5\n",
    "    WHEN cylinders = '4 cylinders' THEN 4\n",
    "    WHEN cylinders = '3 cylinders' THEN 3\n",
    "    WHEN cylinders = '2 cylinders' THEN 2\n",
    "    ELSE cylinders\n",
    "END AS cylinders,\n",
    "CASE\n",
    "    WHEN fuel = 'gas' THEN 1\n",
    "    WHEN fuel = 'electric' THEN 2\n",
    "    WHEN fuel = 'diesel' THEN 3\n",
    "    WHEN fuel = 'hybrid' THEN 4\n",
    "    WHEN fuel = 'other' THEN 5\n",
    "END AS fuel,\n",
    "odometer,\n",
    "CASE\n",
    "    WHEN transmission = 'manual' THEN 1\n",
    "    WHEN transmission = 'automatic' THEN 2\n",
    "    WHEN transmission = 'other' THEN 3\n",
    "END AS transmission,\n",
    "CASE\n",
    "    WHEN drive = 'rwd' THEN 1\n",
    "    WHEN drive = 'fwd' THEN 2\n",
    "    WHEN drive = '4wd' THEN 3\n",
    "END AS drive,\n",
    "CASE\n",
    "    WHEN paint_color = 'black' THEN 1\n",
    "    WHEN paint_color = 'blue' THEN 2\n",
    "    WHEN paint_color = 'brown' THEN 3\n",
    "    WHEN paint_color = 'custom' THEN 4\n",
    "    WHEN paint_color = 'green' THEN 5\n",
    "    WHEN paint_color = 'grey' THEN 6\n",
    "    WHEN paint_color = 'orange' THEN 7\n",
    "    WHEN paint_color = 'purple' THEN 8\n",
    "    WHEN paint_color = 'red' THEN 9\n",
    "    WHEN paint_color = 'silver' THEN 10\n",
    "    WHEN paint_color = 'white' THEN 11\n",
    "    WHEN paint_color = 'yellow' THEN 12\n",
    "END AS paint_color,\n",
    "lat,\n",
    "ABS(long)\n",
    "\n",
    " FROM craigslistVehiclesFull \n",
    " WHERE city = 'losangeles'\n",
    " AND manufacturer IS NOT NULL\n",
    " AND condition IS NOT NULL\n",
    " AND cylinders IS NOT NULL\n",
    " AND cylinders != 'other'\n",
    " AND odometer IS NOT NULL\n",
    " AND transmission IS NOT NULL\n",
    " AND drive IS NOT NULL\n",
    " AND paint_color IS NOT NULL\n",
    " AND lat IS NOT NULL\n",
    " AND long IS NOT NULL\n",
    " \n",
    " AND odometer <= 440000\n",
    " AND price >= 500\n",
    " AND price <= 219000\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "attributes = pd.read_sql(query, conn)\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) I split the data into training/test sets using an 80%/20% split. Note that the train_test_split function shuffles the data by default so no additional parameters are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1442\n",
      "361\n"
     ]
    }
   ],
   "source": [
    "#80-20 train/test split\n",
    "train, test = train_test_split(attributes, test_size=0.2)\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "#convert training data into train_X and train_y\n",
    "train_features = list(train.columns[1:])\n",
    "train_y = train[\"price\"]\n",
    "train_x = train[train_features]\n",
    "\n",
    "#convert testing data into test_X and test_y\n",
    "test_features = list(test.columns[1:])\n",
    "test_y = test[\"price\"]\n",
    "test_x = test[test_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) I trained the decision tree by first optimizing the hyperparameters max_depth and min_samples. This helps improve the accuracy of the tree while also reducing overfitting. 10-fold cross validation is done using 8 threads to complete the evaluation. \n",
    "\n",
    "Note that I used the absolute mean earror for scoring. I'm not sure if this has an impact on accuracy but I did it to have an easy to understand output value (the dollar difference between the predicted & actual price).\n",
    "\n",
    "Then, I output the hyperparameter values and training score of the best tree from the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\n",
      "{'max_depth': 10, 'min_samples_leaf': 7, 'min_samples_split': 15}\n",
      "Best CV Score:\n",
      "4857.768291763836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\graham\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth':range(1,25),\n",
    "    'min_samples_split':range(2,25),\n",
    "    'min_samples_leaf':range(1,25),\n",
    "}\n",
    "model = GridSearchCV(tree.DecisionTreeRegressor(), param_grid, cv=10, n_jobs=8, scoring='neg_mean_absolute_error')\n",
    "model.fit(train_x, train_y)\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) I then stored the best decision tree created by the training process and evaluated it using the testing data set, again using 10-fold cross validation and mean absolute error. The scores output here are close to the best score achieved during training, which shows that the tree isn't overfitting the data.\n",
    "\n",
    "The best prediction value I could get with this method was about 5000 absolute error, so prediction values within +/- $5000 of the actual sale price. Which isn't great but isn't awful either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5470.71795269, -8218.50610932, -9281.35415803, -5739.23314641,\n",
       "       -5366.98537358, -5674.37908026, -6303.39558081, -5240.34747829,\n",
       "       -6089.24035378, -9929.08964608])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = model.best_estimator_\n",
    "scores = cross_val_score(best, test_x, test_y, cv=10, scoring='neg_mean_absolute_error')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b2) I decided to try finding the best features using some sklearn functionality. First I calculated the correlation to price of the other features in the dataset. From this we can see that the most important by far is odometer reading, followed by manufacturer & paint color. Interestingly, Year does not seem to be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[43.212 3456.683 185.801 306.821 211.919 32989934.371 29.911 168.921\\n 1382.842 21.052 73.595]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = attributes.values\n",
    "X = array[:,1:]\n",
    "Y = array[:,0]\n",
    "\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k='all')\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores\n",
    "np.array2string(fit.scores_, formatter={'float_kind':'{0:.3f}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote another query which only includes the top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  odometer  manufacturer  paint_color\n",
      "0      5450    207000            31            9\n",
      "1     12800     34000            37            9\n",
      "2      5995     50000            18            6\n",
      "3     24000    203000            15           11\n",
      "4       500    175235            32            1\n",
      "...     ...       ...           ...          ...\n",
      "2892  17500     39000            34           10\n",
      "2893  17790     43917            17           10\n",
      "2894  18490     45617            17            1\n",
      "2895  14950     22112            14           11\n",
      "2896  22985     76637            14            2\n",
      "\n",
      "[2897 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT \n",
    "price,\n",
    "odometer,\n",
    "CASE\n",
    "\tWHEN manufacturer = 'acura' THEN 1\n",
    "\tWHEN manufacturer = 'alfa-romeo' THEN 2\n",
    "    WHEN manufacturer = 'aston' THEN 3\n",
    "    WHEN manufacturer = 'aston-martin' THEN 3\n",
    "    WHEN manufacturer = 'audi' THEN 4\n",
    "    WHEN manufacturer = 'bmw' THEN 5\n",
    "    WHEN manufacturer = 'buick' THEN 6\n",
    "    WHEN manufacturer = 'cadillac' THEN 7\n",
    "    WHEN manufacturer = 'chev' THEN 8\n",
    "    WHEN manufacturer = 'chevrolet' THEN 8\n",
    "    WHEN manufacturer = 'chevy' THEN 8\n",
    "    WHEN manufacturer = 'chrysler' THEN 9\n",
    "    WHEN manufacturer = 'datsun' THEN 10\n",
    "    WHEN manufacturer = 'dodge' THEN 11\n",
    "    WHEN manufacturer = 'ferrari' THEN 12\n",
    "    WHEN manufacturer = 'fiat' THEN 13\n",
    "    WHEN manufacturer = 'ford' THEN 14\n",
    "    WHEN manufacturer = 'gmc' THEN 15\n",
    "    WHEN manufacturer = 'harley-davidson' THEN 16\n",
    "    WHEN manufacturer = 'honda' THEN 17\n",
    "    WHEN manufacturer = 'hyundai' THEN 18\n",
    "    WHEN manufacturer = 'infiniti' THEN 19\n",
    "    WHEN manufacturer = 'infinity' THEN 19\n",
    "    WHEN manufacturer = 'jaguar' THEN 20\n",
    "    WHEN manufacturer = 'jeep' THEN 21\n",
    "    WHEN manufacturer = 'kia' THEN 22\n",
    "    WHEN manufacturer = 'land rover' THEN 23\n",
    "    WHEN manufacturer = 'rover' THEN 23\n",
    "    WHEN manufacturer = 'lexus' THEN 24\n",
    "    WHEN manufacturer = 'lincoln' THEN 25\n",
    "    WHEN manufacturer = 'mazda' THEN 26\n",
    "    WHEN manufacturer = 'mercedes' THEN 27\n",
    "    WHEN manufacturer = 'mercedes-benz' THEN 27\n",
    "    WHEN manufacturer = 'mercury' THEN 28\n",
    "    WHEN manufacturer = 'mini' THEN 29\n",
    "    WHEN manufacturer = 'mitsubishi' THEN 30\n",
    "    WHEN manufacturer = 'nissan' THEN 31\n",
    "    WHEN manufacturer = 'pontiac' THEN 32\n",
    "    WHEN manufacturer = 'porche' THEN 33\n",
    "    WHEN manufacturer = 'ram' THEN 34\n",
    "    WHEN manufacturer = 'saturn' THEN 35\n",
    "    WHEN manufacturer = 'subaru' THEN 36\n",
    "    WHEN manufacturer = 'toyota' THEN 37\n",
    "    WHEN manufacturer = 'vw' THEN 38\n",
    "    WHEN manufacturer = 'volkswagen' THEN 38\n",
    "    WHEN manufacturer = 'volvo' THEN 39\n",
    "END AS manufacturer,\n",
    "CASE\n",
    "    WHEN paint_color = 'black' THEN 1\n",
    "    WHEN paint_color = 'blue' THEN 2\n",
    "    WHEN paint_color = 'brown' THEN 3\n",
    "    WHEN paint_color = 'custom' THEN 4\n",
    "    WHEN paint_color = 'green' THEN 5\n",
    "    WHEN paint_color = 'grey' THEN 6\n",
    "    WHEN paint_color = 'orange' THEN 7\n",
    "    WHEN paint_color = 'purple' THEN 8\n",
    "    WHEN paint_color = 'red' THEN 9\n",
    "    WHEN paint_color = 'silver' THEN 10\n",
    "    WHEN paint_color = 'white' THEN 11\n",
    "    WHEN paint_color = 'yellow' THEN 12\n",
    "END AS paint_color\n",
    "\n",
    " FROM craigslistVehiclesFull \n",
    " WHERE city = 'losangeles'\n",
    " AND manufacturer IS NOT NULL\n",
    " AND odometer IS NOT NULL\n",
    " AND paint_color IS NOT NULL\n",
    " \n",
    " AND odometer <= 440000\n",
    " AND price >= 500\n",
    " AND price <= 219000\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "attributes2 = pd.read_sql(query2, conn)\n",
    "print(attributes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I repeated the training & testing process to create a new decision tree based on the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317\n",
      "580\n"
     ]
    }
   ],
   "source": [
    "#80-20 train/test split\n",
    "train, test = train_test_split(attributes2, test_size=0.2)\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "#convert training data into train_X and train_y\n",
    "train_features = list(train.columns[1:])\n",
    "train_y = train[\"price\"]\n",
    "train_x = train[train_features]\n",
    "\n",
    "#convert testing data into test_X and test_y\n",
    "test_features = list(test.columns[1:])\n",
    "test_y = test[\"price\"]\n",
    "test_x = test[test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best CV Score:\n",
      "6135.452573501997\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth':range(1,25),\n",
    "    'min_samples_split':range(2,25),\n",
    "    'min_samples_leaf':range(1,25),\n",
    "}\n",
    "model = GridSearchCV(tree.DecisionTreeRegressor(), param_grid, cv=10, n_jobs=8, scoring='neg_mean_absolute_error')\n",
    "model.fit(train_x, train_y)\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, at the end the performance was about the same (or slightly worse). Interestingly though, the new classifier does seem to perform slightly better when evaluated against the testing data set, which suggests that including too many features increases the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6308.51122502, -5087.97576032, -6152.07146792, -4991.37823844,\n",
       "       -5648.91814976, -4851.35657047, -5231.59691329, -5174.85726106,\n",
       "       -6493.50476738, -8027.68881262])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = model.best_estimator_\n",
    "scores = cross_val_score(best, test_x, test_y, cv=10, scoring='neg_mean_absolute_error')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This was a fun project for me because it involved working with regression, whereas my previous Datamining project was based on classifiction. It was interesting to see how the techniques differ and where they are the same. \n",
    "\n",
    "The final performance of the decision trees wasn't great, but I have a lot of ideas for how performance could be improved. Such as focusing on lower-priced vehicles which seem to have less variance, or doing more work to fine tune the feature selection and hyperparameters. Also, it would be interesting to try out other machine learning techniques on this dataset, such as the Random Forests described in Question 1, or SVM (Support Vector Machine) techniques, which we found had the best performance in my Datamining project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
